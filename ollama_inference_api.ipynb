{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import pandas as pd\n",
    "import ollama \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "# 数据集路径\n",
    "IMAGE_DIR_1 = \"data/HAM10000/HAM10000_images_part_1\"\n",
    "IMAGE_DIR_2 = \"data/HAM10000/HAM10000_images_part_2\"\n",
    "METADATA_FILE = \"data/HAM10000/HAM10000_metadata.csv\"\n",
    "\n",
    "# 结果和检查点路径\n",
    "RESULTS_FILE = \"ollama_native_classification_results.csv\" # 建议换个新文件名以区分\n",
    "CHECKPOINT_FILE = \"ollama_native_checkpoint.json\"       # 建议换个新文件名以区分\n",
    "\n",
    "# 用于分类的类别列表\n",
    "categories = [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]\n",
    "categories_str = \", \".join(categories)\n",
    "\n",
    "# 视觉语言模型的提示 (保持不变)\n",
    "PROMPT_TEXT = f\"\"\"\n",
    "你是一名世界级的皮肤科AI诊断助手。请按照以下步骤分析和分类提供的皮肤镜图像。\n",
    "\n",
    "**第一步：特征分析（内心思考，不要输出）**\n",
    "1.  **对称性**：病变的形状是否对称？\n",
    "2.  **边缘**：边缘是清晰规则，还是模糊、不规则、有切迹？\n",
    "3.  **颜色**：颜色是单一均匀，还是包含多种颜色（如棕、黑、红、蓝、白）？颜色分布是否均匀？\n",
    "4.  **结构**：是否能观察到特定的皮肤镜结构？例如，色素网络、点状血管、树枝状血管、蓝白幕、乳头状结构等。\n",
    "5.  **整体评估**：综合以上特征，病变给人的整体感觉是良性的（有序、规则）还是恶性的（混乱、不规则）？\n",
    "\n",
    "**第二步：分类判断**\n",
    "根据你的分析，将图像归类到以下七个类别之一：{categories_str}。\n",
    "    - **黑色素瘤 (mel, Melanoma)** 特征：明显的不对称性、不规则边缘、颜色多样性（棕、黑、蓝、白、红等），  \n",
    "      非典型色素网络、蓝白幕、放射状线条、负网状结构、不对称的小点或条纹、局部回避区等恶性特征。 \n",
    " \n",
    "    - **基底细胞癌 (bcc, Basal Cell Carcinoma)** 特征：树枝状血管、蓝灰色卵圆巢、光滑珠光边缘、溃疡或结痂区域、车轮辐射状结构、白色条纹或亮点。 \n",
    " \n",
    "    - **黑色素细胞痣 (nv, Melanocytic Nevus)** 特征：整体对称、规则的色素网络、均匀的棕色色调、清晰边界、  \n",
    "      可见规则点状或球状结构、均匀分布的色素网格。 \n",
    " \n",
    "    - **脂溢性角化病 (bkl, Benign Keratosis)** 特征：粉刺样开口、脑回状（丘脑状）结构、粘贴感外观、白色假网状结构、角质栓、黑点或伪毛囊口。 \n",
    " \n",
    "    - **光化性角化病 (akiec, Actinic Keratosis)** 特征：红白交错的表面、毛细血管扩张、鳞屑、角质过度增生、淡棕或红色调，  \n",
    "      可能可见“草地样”或“红白斑块状”结构。 \n",
    " \n",
    "    - **皮肤纤维瘤 (df, Dermatofibroma)** 特征：中心棕色区伴周围淡色晕、放射状色素结构、中心瘢痕样白区、周边色素网络逐渐消退、轻微凹陷。 \n",
    " \n",
    "    - **血管性病变 (vasc, Vascular Lesion)** 特征：均匀的红色至紫色区域、清晰可见的血管结构、点状或线状血管、湖状血管样分布、整体对称。\n",
    "\n",
    "**第三步：输出结果**\n",
    "请只输出最终确定的类别缩写。不要包含任何分析、解释或额外文字。\n",
    "\"\"\"\n",
    "\n",
    "# --- 2. 辅助函数 ---\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"将图像文件编码为base64字符串。\"\"\"\n",
    "    try:\n",
    "        # 在原生 Ollama 库中，可以直接传递原始字节，但为了保持与多进程的兼容性，\n",
    "        # 传递 base64 字符串仍然是一个好方法。\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"编码图像 {image_path} 时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "def classify_image(image_id, image_path):\n",
    "    \"\"\"\n",
    "    使用Ollama模型对单个图像进行分类。\n",
    "    返回一个元组 (image_id, result_dict)。\n",
    "    \"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "    if not base64_image:\n",
    "        return image_id, None\n",
    "\n",
    "    try:\n",
    "        # --- 2. 使用原生 ollama.chat 进行 API 调用 ---\n",
    "        response = ollama.chat(\n",
    "            model=\"qwen2.5vl:32b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': PROMPT_TEXT,\n",
    "                }\n",
    "            ],\n",
    "            # 将图片作为独立的参数传递\n",
    "            images=[base64_image],\n",
    "            # 可以通过 options 传递参数，但对于简短回复，模型通常能遵循指令\n",
    "            options={\n",
    "                'num_predict': 10 \n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # --- 3. 修改响应解析方式 ---\n",
    "        predicted_class = response['message']['content'].strip().lower()\n",
    "\n",
    "        # 验证模型的输出 (保持不变)\n",
    "        if predicted_class not in categories:\n",
    "            print(f\"警告：图像 {image_id} 的模型返回了一个意外的类别 '{predicted_class}'。将其设置为'unknown'。\")\n",
    "            predicted_class = \"unknown\"\n",
    "\n",
    "        return image_id, {\"predicted_class\": predicted_class}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"分类图像 {image_id} 时出错: {e}\")\n",
    "        return image_id, None\n",
    "\n",
    "def load_checkpoint():\n",
    "    \"\"\"从检查点文件加载已处理的图像和结果。\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            return set(data.get(\"processed_images\", [])), data.get(\"results\", {})\n",
    "    return set(), {}\n",
    "\n",
    "def save_checkpoint(processed_images, results):\n",
    "    \"\"\"将已处理的图像和结果保存到检查点文件。\"\"\"\n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        json.dump({\"processed_images\": list(processed_images), \"results\": results}, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 开始图像分类 (使用原生 Ollama) ---\") # <--- 更新了打印信息\n",
    "# 加载元数据\n",
    "metadata_df = pd.read_csv(METADATA_FILE)\n",
    "print(f\"已加载 {len(metadata_df)} 张图像的元数据。\")\n",
    "# 获取所有图像路径\n",
    "image_paths_part1 = glob.glob(os.path.join(IMAGE_DIR_1, '*.jpg'))\n",
    "image_paths_part2 = glob.glob(os.path.join(IMAGE_DIR_2, '*.jpg'))\n",
    "all_image_paths = image_paths_part1 + image_paths_part2\n",
    "\n",
    "image_id_to_path = {os.path.basename(p).split('.')[0]: p for p in all_image_paths}\n",
    "print(f\"共找到 {len(all_image_paths)} 张图像。\")\n",
    "# 从检查点加载\n",
    "processed_ids, results = load_checkpoint()\n",
    "print(f\"已加载检查点。{len(processed_ids)} 张图像已被处理。\")\n",
    "# 确定要处理的图像\n",
    "unprocessed_tasks = []\n",
    "for img_id in metadata_df['image_id']:\n",
    "    if img_id not in processed_ids and img_id in image_id_to_path:\n",
    "        unprocessed_tasks.append((img_id, image_id_to_path[img_id]))\n",
    "\n",
    "print(f\"找到 {len(unprocessed_tasks)} 张待处理的图像。\")\n",
    "if not unprocessed_tasks:\n",
    "    print(\"没有新的图像需要处理。\")\n",
    "else:\n",
    "    # 并行处理\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # 为未处理的图像创建future\n",
    "        futures = {executor.submit(classify_image, img_id, path): (img_id, path) for img_id, path in unprocessed_tasks}\n",
    "        \n",
    "        # 在任务完成时处理结果\n",
    "        for future in tqdm(as_completed(futures), total=len(unprocessed_tasks), desc=\"正在分类图像\"):\n",
    "            image_id, result = future.result()\n",
    "            if result:\n",
    "                results[image_id] = result\n",
    "                processed_ids.add(image_id)\n",
    "                \n",
    "                # 定期保存检查点（例如，每处理10张图像）\n",
    "                if len(processed_ids) % 10 == 0:\n",
    "                    save_checkpoint(processed_ids, results)\n",
    "# 最后保存检查点和结果\n",
    "print(\"分类完成。正在保存最终结果...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(processed_ids, results)\n",
    "# 将结果转换为DataFrame并保存为CSV\n",
    "results_list = []\n",
    "for image_id, result_data in results.items():\n",
    "    results_list.append({\n",
    "        \"image_id\": image_id,\n",
    "        \"predicted_class\": result_data.get(\"predicted_class\", \"error\")\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(RESULTS_FILE, index=False)\n",
    "print(f\"结果已保存到 {RESULTS_FILE}\")\n",
    "# --- 4. 评估 ---\n",
    "print(\"\\n--- 正在评估准确率 ---\")\n",
    "# 确保结果文件存在再进行评估\n",
    "if not os.path.exists(RESULTS_FILE) or len(results_df) == 0:\n",
    "    print(\"没有可评估的结果。\")\n",
    "    \n",
    "merged_df = pd.merge(results_df, metadata_df[['image_id', 'dx']], on='image_id', how='inner')\n",
    "merged_df = merged_df.rename(columns={'dx': 'true_class'})\n",
    "correct_predictions = (merged_df['predicted_class'] == merged_df['true_class']).sum()\n",
    "total_predictions = len(merged_df)\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"总评估预测数: {total_predictions}\")\n",
    "print(f\"正确预测数: {correct_predictions}\")\n",
    "print(f\"总体准确率: {accuracy:.4f}\")\n",
    "# 各类别准确率\n",
    "if total_predictions > 0:\n",
    "    class_accuracy = merged_df.groupby('true_class').apply(\n",
    "        lambda x: (x['predicted_class'] == x['true_class']).mean()\n",
    "    ).reset_index(name='accuracy')\n",
    "    print(\"\\n各类别准确率:\")\n",
    "    print(class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63e1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
