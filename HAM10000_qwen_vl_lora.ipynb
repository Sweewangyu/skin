{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import bitsandbytes as bnb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 数据路径\n",
    "data_dir = \"/Users/mac/Desktop/lunwen/code/HAM10000_dataset\"\n",
    "metadata_path = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
    "images_dir = os.path.join(data_dir, \"images\")\n",
    "\n",
    "# 读取元数据\n",
    "df = pd.read_csv(metadata_path)\n",
    "print(f\"数据集大小: {len(df)}\")\n",
    "print(df.head())\n",
    "\n",
    "# 查看类别分布\n",
    "print(df['dx'].value_counts())\n",
    "\n",
    "# 类别映射\n",
    "class_dict = {\n",
    "    'akiec': '光化性角化病和上皮内癌',\n",
    "    'bcc': '基底细胞癌',\n",
    "    'bkl': '良性角化病',\n",
    "    'df': '皮肤纤维瘤',\n",
    "    'mel': '黑色素瘤',\n",
    "    'nv': '黑素细胞痣',\n",
    "    'vasc': '血管病变'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建自定义数据集\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, tokenizer, max_length=512):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_id = row['image_id']\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 构建提示文本\n",
    "        prompt = f\"<img>这是什么类型的皮肤病变？请从以下选项中选择：光化性角化病和上皮内癌、基底细胞癌、良性角化病、皮肤纤维瘤、黑色素瘤、黑素细胞痣、血管病变。\"\n",
    "        \n",
    "        # 构建目标文本\n",
    "        target = class_dict[row['dx']]\n",
    "        \n",
    "        # 编码输入\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # 添加图像到输入\n",
    "        inputs[\"images\"] = self.tokenizer.process_images(image)\n",
    "        \n",
    "        # 编码目标\n",
    "        target_encoding = self.tokenizer(\n",
    "            target,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # 准备模型输入\n",
    "        input_ids = inputs[\"input_ids\"][0]\n",
    "        attention_mask = inputs[\"attention_mask\"][0]\n",
    "        images = inputs[\"images\"][0]\n",
    "        \n",
    "        # 准备标签\n",
    "        labels = target_encoding[\"input_ids\"][0]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"images\": images,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "# 加载Qwen-VL模型和分词器\n",
    "model_name = \"Qwen/Qwen-VL-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "# 准备模型进行LoRA微调\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# 配置LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRA的秩\n",
    "    lora_alpha=32,  # LoRA的alpha参数\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # 目标模块\n",
    "    lora_dropout=0.05,  # LoRA的dropout率\n",
    "    bias=\"none\",  # 是否包含偏置项\n",
    "    task_type=\"CAUSAL_LM\"  # 任务类型\n",
    ")\n",
    "\n",
    "# 应用LoRA配置\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(f\"模型参数总数: {model.num_parameters()}\")\n",
    "print(f\"可训练参数数量: {model.num_parameters(True)}\")\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['dx'])\n",
    "print(f\"训练集大小: {len(train_df)}, 验证集大小: {len(val_df)}\")\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = HAM10000Dataset(train_df, images_dir, tokenizer)\n",
    "val_dataset = HAM10000Dataset(val_df, images_dir, tokenizer)\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/Users/mac/Desktop/lunwen/code/qwen_vl_ham10000_lora\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# 定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "trainer.save_model(\"/Users/mac/Desktop/lunwen/code/qwen_vl_ham10000_lora/final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "def evaluate_model(model, dataset, tokenizer):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=4)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"评估中\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            images = batch[\"images\"].to(device)\n",
    "            \n",
    "            # 获取模型输出\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                images=images,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=False\n",
    "            )\n",
    "            \n",
    "            # 解码预测结果\n",
    "            pred_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            \n",
    "            # 解码真实标签\n",
    "            true_texts = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "            \n",
    "            # 将预测结果映射到类别\n",
    "            for pred_text in pred_texts:\n",
    "                for class_key, class_name in class_dict.items():\n",
    "                    if class_name in pred_text:\n",
    "                        predictions.append(class_key)\n",
    "                        break\n",
    "                else:\n",
    "                    # 如果没有找到匹配的类别，选择最相似的\n",
    "                    max_similarity = 0\n",
    "                    best_class = None\n",
    "                    for class_key, class_name in class_dict.items():\n",
    "                        similarity = sum(1 for a, b in zip(pred_text, class_name) if a == b) / max(len(pred_text), len(class_name))\n",
    "                        if similarity > max_similarity:\n",
    "                            max_similarity = similarity\n",
    "                            best_class = class_key\n",
    "                    predictions.append(best_class)\n",
    "            \n",
    "            # 将真实标签映射到类别\n",
    "            for true_text in true_texts:\n",
    "                for class_key, class_name in class_dict.items():\n",
    "                    if class_name in true_text:\n",
    "                        true_labels.append(class_key)\n",
    "                        break\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions, target_names=list(class_dict.values()))\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "# 评估模型\n",
    "accuracy, report = evaluate_model(model, val_dataset, tokenizer)\n",
    "print(f\"验证集准确率: {accuracy:.4f}\")\n",
    "print(\"分类报告:\")\n",
    "print(report)\n",
    "\n",
    "# 可视化一些预测结果\n",
    "def visualize_predictions(model, dataset, tokenizer, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        sample = dataset[idx]\n",
    "        \n",
    "        # 获取图像\n",
    "        row = dataset.dataframe.iloc[idx]\n",
    "        img_id = row['image_id']\n",
    "        img_path = os.path.join(dataset.img_dir, f\"{img_id}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 获取真实标签\n",
    "        true_label = row['dx']\n",
    "        true_label_name = class_dict[true_label]\n",
    "        \n",
    "        # 获取模型预测\n",
    "        with torch.no_grad():\n",
    "            input_ids = sample[\"input_ids\"].unsqueeze(0).to(device)\n",
    "            attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "            images = sample[\"images\"].unsqueeze(0).to(device)\n",
    "            \n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                images=images,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=False\n",
    "            )\n",
    "            \n",
    "            pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # 从预测文本中提取类别\n",
    "            pred_label_name = \"未知\"\n",
    "            for class_key, class_name in class_dict.items():\n",
    "                if class_name in pred_text:\n",
    "                    pred_label_name = class_name\n",
    "                    break\n",
    "        \n",
    "        # 显示图像和预测结果\n",
    "        plt.subplot(num_samples, 2, 2*i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"真实: {true_label_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 2, 2*i+2)\n",
    "        plt.text(0.1, 0.5, f\"预测: {pred_label_name}\\n\\n完整回答:\\n{pred_text}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"/Users/mac/Desktop/lunwen/code/qwen_vl_ham10000_predictions.png\")\n",
    "    plt.show()\n",
    "\n",
    "# 可视化一些预测结果\n",
    "visualize_predictions(model, val_dataset, tokenizer)\n",
    "\n",
    "print(\"训练和评估完成！\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
